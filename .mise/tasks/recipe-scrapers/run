#!./.venv/bin/python
# mise description="Scrape recipes from the web and store them in a local directory"

from recipe_scrapers import scrape_me
import argparse
import json


# Get the first CLI argument
parser = argparse.ArgumentParser()
parser.add_argument("url", type=str, help="The URL to scrape")
params = parser.parse_args()

scraped = scrape_me(
    # "https://mere.eirik.re/hovedrett/char-siu-inspirert-kjottdeig/", wild_mode=True,
    params.url,
    wild_mode=True,
    # "https://www.hellofresh.no/recipes/char-siu-inspirert-kjottdeig-63ea00c81c9cdaabe476a6c2",
)

methods = {
    # "canonical_url",
    # "cooking_method",
    # "dietary_restrictions",
    # "equipment",
    # "host",
    # "image",
    # "ingredient_groups",
    # "ingredients",
    # "instructions",
    # "instructions_list",
    # "keywords",
    # # "links",  # just a big object of all links on the page
    # "nutrients",
    # "title",
    "to_json",
    # "total_time",
    # "yields",
    # "ratings",
}


def print_info(method: str) -> None:
    """Prints the information from the scraper."""
    try:
        info = getattr(scraped, method)()
    except Exception as _:
        pass
    else:
        print(json.dumps(info, indent=2))


for m in methods:
    print_info(m)
